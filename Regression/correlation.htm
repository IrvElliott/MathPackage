<html>

<head>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<meta name="GENERATOR" content="Microsoft FrontPage 4.0">
<meta name="ProgId" content="FrontPage.Editor.Document">
<title>CORRELATION</title>
</head>

<body>

<font FACE="Times New Roman" LANG="JA">
<p>CORRELATION</p>
<p>In review: the regression calculation has two steps: (1) from m sets of
measurements of n independent variables and one dependent variable, form a
system of n simultaneous equations for n unknowns and (2) solve the simultaneous
equations. There are certain conditions for which the solution to a set of
simultaneous equations cannot be solved. If one equation of the set of n
equations is a multiple of another equation of the set, one of those equations
would be redundant and thus the system would only have m-1 meaningful equations;
thus, the system could not be solved. Similarly, it can be shown that, if one
column of values for a particular variable is a multiple of another, the system
will also be unsolvable.</p>
<p>When the calculations are performed on a computer, a problem may occur when
one row is <u>almost</u> the multiple of another. A similar problem may occur if
a column is almost a multiple of another. This may causes a numeric overflow; an
attempt to form a number that is too large to represent in the computer's
system.</p>
<p>In a regression calculation, errors of these sorts occur when a variable that
was chosen to be independent is, instead, very similar to some other variable
that was chosen to be independent. To check for these conditions in the
regression X matrix, we can calculate the “correlation coefficient” for each
combination of two columns. This coefficient ranges from 0 to 1. If the value is
0, the columns are not similar. If the value is 1, they are similar and one of
the two columns should be eliminated and the corresponding variable should be
dropped from the problem.</p>
<p>The correlation coefficient is easier to explain if we review some simple
vector math. A vector is a set of two or more numbers, sometimes represented in
parentheses or square brackets and usually separated by commas. If a vector has
m elements, it is said to be “m-dimensional”. A two or three dimensional
vector is often used to represent a direction and a magnitude, such as on a map
of wind speeds. Four two-dimensional vectors identified as A, B, C and D are
shown in the following figure.</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<img border="0" src="vectors.jpg" width="355" height="429"></p>
<p>The “magnitude” of any vector, denoted by surrounding the vector
identifier with vertical bars, is equal to the square root of the sum of the
squares of its elements; thus, for vector A, the magnitude (length) is the
square root of 16+9, or 5. To us, for a vector of m dimensions, the magnitude
may be difficult to imagine because we live in a three dimensional world;
however, it is defined in the same way, as</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<img border="0" src="mag.jpg" width="169" height="91"></p>
<p>For the regression problem, each column of the X matrix should be paired with
the other columns and the correlation coefficients for each pair should be
examined. This can be a byproduct of step 1 of the regression calculation: the
matrix multiplication of X by the transpose of X. For example, if the input data
X matrix is 10 by 4, we can denote the four columns of X as vectors X1, X2, X3
and X4. Using the dot product notation, the matrix resulting from the matrix
multiplication of the regression step two calculation is shown below on the
left. A matrix of correlation coefficients can be generated by copying this
matrix and then dividing each element by the absolute values of the vectors used
to obtain the dot product, as shown on the right.</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<img border="0" src="dotprod.jpg" width="318" height="94"></p>
</font><font FACE="Times New Roman" LANG="JA">
<p>For a perfect case, in which all of the X column vectors are orthogonal to
each other, the n by n matrix and the correlation matrix would be as follows:</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<img border="0" src="costheta.jpg" width="304" height="73"></p>
<p>If we are fitting curves for many sets of Y data and are using a set of
orthogonal functions for the X matrix, we could greatly simplify the task. Step
2 of the regression calculation would simply consist of dividing each Y value by
the corresponding dot product on the matrix diagonal.</p>
</font>

</body>

</html>
